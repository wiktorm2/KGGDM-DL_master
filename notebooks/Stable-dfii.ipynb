{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from diffusers import AutoencoderKL, UNet2DConditionModel, DDPMScheduler\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "import argparse\n",
    "import traceback\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--resume', action='store_true', help='Resume training from latest checkpoint')\n",
    "    parser.add_argument('--checkpoint', type=str, default=None, help='Specific checkpoint path to resume from')\n",
    "    return parser.parse_args()\n",
    "\n",
    "def load_checkpoint(checkpoint_path, unet, proj, optimizer):\n",
    "    \"\"\"Load model and optimizer states from checkpoint\"\"\"\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    unet.load_state_dict(checkpoint['unet'])\n",
    "    proj.load_state_dict(checkpoint['proj'])\n",
    "    if optimizer and 'optimizer' in checkpoint:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    epoch = checkpoint.get('epoch', 0)\n",
    "    step = checkpoint.get('step', 0)\n",
    "    print(f\"âœ… Loaded checkpoint from epoch {epoch}, step {step}\")\n",
    "    return epoch, step\n",
    "\n",
    "def save_checkpoint(epoch, step, unet, proj, optimizer, output_dir, prefix='epoch'):\n",
    "    \"\"\"Save training state\"\"\"\n",
    "    ckpt_path = output_dir / f\"{prefix}_{epoch:03d}_step{step:06d}.pt\"\n",
    "    torch.save({\n",
    "        'unet': unet.state_dict(),\n",
    "        'proj': proj.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'epoch': epoch,\n",
    "        'step': step\n",
    "    }, ckpt_path)\n",
    "    # Also save as latest\n",
    "    torch.save({\n",
    "        'unet': unet.state_dict(),\n",
    "        'proj': proj.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'epoch': epoch,\n",
    "        'step': step\n",
    "    }, output_dir / \"latest_checkpoint.pt\")\n",
    "    return ckpt_path\n",
    "\n",
    "class CelebALatentDataset(Dataset):\n",
    "    def __init__(self, precomputed_latents, attr_codes, scheduler, device):\n",
    "        self.latents = precomputed_latents\n",
    "        self.attr_codes = attr_codes\n",
    "        self.scheduler = scheduler\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.latents)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        latent = self.latents[idx]\n",
    "        noise = torch.randn_like(latent)\n",
    "        t = torch.randint(0, self.scheduler.config.num_train_timesteps, (1,)).long()\n",
    "        noisy_latent = self.scheduler.add_noise(latent.unsqueeze(0), noise.unsqueeze(0), t).squeeze(0)\n",
    "        cond = self.attr_codes[idx].float()\n",
    "        return noisy_latent, t.squeeze(0), noise, cond\n",
    "\n",
    "def main():\n",
    "    args = parse_args()\n",
    "\n",
    "    try:\n",
    "        # =====================================================================\n",
    "        # 1. Initialization\n",
    "        # =====================================================================\n",
    "        print(\"=\"*80)\n",
    "        print(\"STARTING SCRIPT EXECUTION\")\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f\"PyTorch: {torch.__version__}\")\n",
    "        print(f\"Device: {device}\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "        # =====================================================================\n",
    "        # 2. Configuration\n",
    "        # =====================================================================\n",
    "        IMG_DIR = Path(\"/mnt/beegfs/home/gs113310/KGGD-project/img_align_celeba/img_align_celeba\")\n",
    "        ATTR_PATH = Path(\"/mnt/beegfs/home/gs113310/KGGD-project/compressed_attr_vectors.npy\")\n",
    "        OUTPUT_DIR = Path(\"/mnt/beegfs/home/gs113310/KGGD-project/sd_checkpoints\")\n",
    "        LATENTS_PATH = OUTPUT_DIR / \"precomputed_latents.pt\"\n",
    "        OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # =====================================================================\n",
    "        # 3. Load Data and Models\n",
    "        # =====================================================================\n",
    "        print(\"Loading data and models...\")\n",
    "        attr_codes = torch.from_numpy(np.load(ATTR_PATH)).float()\n",
    "\n",
    "        vae = AutoencoderKL.from_pretrained(\n",
    "            \"runwayml/stable-diffusion-v1-5\",\n",
    "            subfolder=\"vae\"\n",
    "        ).to(device)\n",
    "\n",
    "        unet = UNet2DConditionModel.from_pretrained(\n",
    "            \"runwayml/stable-diffusion-v1-5\",\n",
    "            subfolder=\"unet\"\n",
    "        ).to(device)\n",
    "\n",
    "        scheduler = DDPMScheduler.from_pretrained(\n",
    "            \"runwayml/stable-diffusion-v1-5\",\n",
    "            subfolder=\"scheduler\"\n",
    "        )\n",
    "\n",
    "        # =====================================================================\n",
    "        # 4. Projection and Dataset Setup\n",
    "        # =====================================================================\n",
    "        proj = nn.Sequential(\n",
    "            nn.Linear(128, unet.config.cross_attention_dim),\n",
    "            nn.Unflatten(1, (1, -1))  # [batch, 1, 768]\n",
    "        ).to(device)\n",
    "\n",
    "        # Load or compute latents\n",
    "        if not LATENTS_PATH.exists():\n",
    "            print(\"Precomputing VAE latents...\")\n",
    "            preprocess = transforms.Compose([\n",
    "                transforms.Resize((512, 512)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.5], [0.5])\n",
    "            ])\n",
    "\n",
    "            image_paths = sorted(IMG_DIR.glob(\"*.jpg\"))\n",
    "            all_latents = []\n",
    "            vae.eval()\n",
    "            with torch.no_grad():\n",
    "                for i, path in enumerate(tqdm(image_paths)):\n",
    "                    img = Image.open(path).convert(\"RGB\")\n",
    "                    img = preprocess(img).unsqueeze(0).to(device)\n",
    "                    latents = vae.encode(img).latent_dist.sample() * vae.config.scaling_factor\n",
    "                    all_latents.append(latents.cpu())\n",
    "                    if i % 1000 == 0:\n",
    "                        torch.cuda.empty_cache()\n",
    "\n",
    "            all_latents = torch.cat(all_latents, dim=0)\n",
    "            torch.save(all_latents, LATENTS_PATH)\n",
    "\n",
    "        precomputed_latents = torch.load(LATENTS_PATH)\n",
    "        dataset = CelebALatentDataset(precomputed_latents, attr_codes, scheduler, device)\n",
    "        loader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "        # =====================================================================\n",
    "        # 5. Training Setup with Resume Capability\n",
    "        # =====================================================================\n",
    "        optimizer = optim.AdamW(list(unet.parameters()) + list(proj.parameters()), lr=1e-4)\n",
    "        mse_loss = nn.MSELoss()\n",
    "        num_epochs = 5\n",
    "\n",
    "        # Resume logic\n",
    "        start_epoch = 1\n",
    "        start_step = 0\n",
    "        if args.resume or args.checkpoint:\n",
    "            checkpoint_path = args.checkpoint if args.checkpoint else OUTPUT_DIR / \"latest_checkpoint.pt\"\n",
    "            start_epoch, start_step = load_checkpoint(checkpoint_path, unet, proj, optimizer)\n",
    "            print(f\"Resuming from epoch {start_epoch}, step {start_step}\")\n",
    "\n",
    "        # Skip already processed steps if resuming\n",
    "        if start_step > 0:\n",
    "            print(f\"Skipping first {start_step} steps...\")\n",
    "            loader = list(loader)[start_step:]\n",
    "\n",
    "        # =====================================================================\n",
    "        # 6. Training Loop with Checkpointing\n",
    "        # =====================================================================\n",
    "        print(f\"ðŸš€ Starting training from epoch {start_epoch}...\")\n",
    "        for epoch in range(start_epoch, num_epochs + 1):\n",
    "            try:\n",
    "                unet.train()\n",
    "                proj.train()\n",
    "                epoch_loss = 0.0\n",
    "\n",
    "                pbar = tqdm(loader, desc=f\"Epoch {epoch}/{num_epochs}\")\n",
    "                for step, (noisy_latents, timesteps, noise, cond) in enumerate(pbar, start=1):\n",
    "                    # Skip steps if resuming\n",
    "                    if epoch == start_epoch and step < start_step:\n",
    "                        continue\n",
    "\n",
    "                    # Move data to device\n",
    "                    noisy_latents = noisy_latents.to(device, non_blocking=True)\n",
    "                    timesteps = timesteps.to(device, non_blocking=True)\n",
    "                    noise = noise.to(device, non_blocking=True)\n",
    "                    cond = proj(cond.to(device, non_blocking=True))\n",
    "\n",
    "                    # Forward pass\n",
    "                    pred = unet(noisy_latents, timesteps, encoder_hidden_states=cond).sample\n",
    "                    loss = mse_loss(pred, noise)\n",
    "\n",
    "                    # Backward pass\n",
    "                    optimizer.zero_grad(set_to_none=True)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    epoch_loss += loss.item()\n",
    "                    pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
    "\n",
    "                    # Save checkpoint every 1000 steps\n",
    "                    if step % 1000 == 0:\n",
    "                        ckpt_path = save_checkpoint(epoch, step, unet, proj, optimizer, OUTPUT_DIR, \"interim\")\n",
    "                        print(f\"Saved interim checkpoint to {ckpt_path}\")\n",
    "                        torch.cuda.empty_cache()\n",
    "\n",
    "                # Save epoch checkpoint\n",
    "                avg_loss = epoch_loss / len(loader)\n",
    "                print(f\"âœ… Epoch {epoch} complete - Avg Loss: {avg_loss:.6f}\")\n",
    "                ckpt_path = save_checkpoint(epoch, 0, unet, proj, optimizer, OUTPUT_DIR)\n",
    "                print(f\"Saved checkpoint to {ckpt_path}\")\n",
    "                raise\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Training failed: {str(e)}\")\n",
    "        sys.exit(1)\n",
    "    finally:\n",
    "        print(\"SCRIPT COMPLETED\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
